from flask import Flask
import pandas as pd
from sqlalchemy import text
from flask_sqlalchemy import SQLAlchemy
import logging
app = Flask(__name__)

db_user = 'postgres'
db_pass = 'password'
db_host = 'localhost'
db_name = 'lightdb'
db_port = '5432'

app.config['SQLALCHEMY_DATABASE_URI'] = f'postgresql://{db_user}:{db_pass}@{db_host}:{db_port}/{db_name}'
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

db = SQLAlchemy(app)
logging.basicConfig(level=logging.INFO)
@app.route('/')
def index():
    return (
        "<h1>Aplicação Flask de Preparação de Dados!</h1>"
        "<p>Acesse /adicionar-localizacao-cidade-estado para adicionar cidade_estado à tabela de localização.</p>"
        "<p>Acesse /processar-cidades-sinalizar-duplicadas para limpar e sinalizar duplicados.</p>"
    )


@app.route('/adicionar-localizacao-cidade-estado')
def preparar_dim_localizacao():
    """
    Esta rota altera a tabela 'public_analytics.dim_localizacao' para:
    1. Adicionar a coluna 'chave_estado_cidade_key' (se não existir).
    2. Preencher esta coluna com a junção de 'cidade' e 'estado' (ex: 'Mendes_RJ').
    """
    logging.info("Iniciando preparação da 'dim_localizacao'...")

    # SQL (PostgreSQL) para adicionar a coluna.
    # 'IF NOT EXISTS' torna a operação segura para rodar múltiplas vezes.
    sql_alter_table = text("""
                           ALTER TABLE public_analytics.dim_localizacao
                               ADD COLUMN IF NOT EXISTS chave_estado_cidade_key VARCHAR (255);
                           """)

    # SQL (PostgreSQL) para preencher a nova coluna.
    # Usamos a sintaxe UPDATE...FROM... para fazer a junção.
    sql_update_data = text("""
                           UPDATE public_analytics.dim_localizacao AS l
                           SET chave_estado_cidade_key = l.cidade || '_' || e.estado FROM public_analytics.dim_estado AS e
                           WHERE l.id_estado = e.id_estado;
                           """)

    try:
        logging.info("Executando: ALTER TABLE...")
        db.session.execute(sql_alter_table)

        logging.info("Executando: UPDATE... FROM...")
        resultado = db.session.execute(sql_update_data)

        db.session.commit()

        linhas_afetadas = resultado.rowcount

        logging.info(f"Preparação concluída! {linhas_afetadas} linhas foram atualizadas.")

        return (
            f"<h1>Preparação Concluída!</h1>"
            f"<p>A tabela <strong>public_analytics.dim_localizacao</strong> foi preparada com sucesso.</p>"
            f"<p>{linhas_afetadas} linhas tiveram a coluna 'chave_estado_cidade_key' preenchida.</p>"
        )

    except Exception as e:
        db.session.rollback()
        logging.error(f"ERRO NA PREPARAÇÃO: {e}")
        return f"<h1>Ocorreu um erro ao preparar a tabela</h1><p>{e}</p>"


@app.route('/processar-cidades-sinalizar-duplicadas')
def processar_cidades_sinalizar_duplicadas():
    """
    Processo de ETL Modificativo:
    1. MODIFICA 'dim_localizacao' (original) adicionando colunas de status ('VALID'/'DUPLICATE_ERROR').
    2. CRIA a VIEW 'dim_localizacao_limpa' (filtrando apenas os 'VALID' da tabela original).
    3. ENRIQUECE 'clientes_bruto' usando a VIEW limpa e salva em 'clientes_enriquecido'.
    """

    # --- ETAPA 1: SINALIZAR A TABELA ORIGINAL (SQL) - VERSÃO CORRIGIDA ---
    logging.info("ETAPA 1: Sinalizando a tabela original 'dim_localizacao'...")

    # 1a. ALTERAR a tabela (adicionar colunas).
    sql_etapa_1_alter = text("""
                             ALTER TABLE public_analytics.dim_localizacao
                                 ADD COLUMN IF NOT EXISTS chave_estado_cidade_key VARCHAR (255),
                                 ADD COLUMN IF NOT EXISTS dq_status VARCHAR (50);
                             """)

    # 1b. ATUALIZAR os dados (com a lógica de detecção).
    # CORREÇÃO: Adicionado TRIM() e LOWER() para garantir a robustez contra espaços e maiúsculas/minúsculas.
    sql_etapa_1_update = text("""
                              WITH ranked_locations AS (SELECT l.id_localizacao,
                                                               -- Limpamos os dados para a chave e para a partição
                                                               TRIM(LOWER(l.cidade)) || '_' || TRIM(LOWER(e.estado)) AS chave_estado_cidade_key_calc,
                                                               ROW_NUMBER()                                             OVER(
                    PARTITION BY TRIM(LOWER(l.cidade)), TRIM(LOWER(e.estado))
                    ORDER BY l.id_localizacao
                ) as rn
                                                        FROM public_analytics.dim_localizacao AS l
                                                                 JOIN
                                                             public_analytics.dim_estado AS e ON l.id_estado = e.id_estado)
                              UPDATE public_analytics.dim_localizacao AS t
                              SET chave_estado_cidade_key = r.chave_estado_cidade_key_calc,
                                  dq_status               = CASE
                                                                WHEN r.rn = 1 THEN 'VALID'
                                                                ELSE 'DUPLICATE_ERROR'
                                      END FROM ranked_locations AS r
                              WHERE t.id_localizacao = r.id_localizacao;
                              """)

    try:
        # Usamos uma única transação para os dois comandos, garantindo a execução sequencial
        with db.session.begin():
            logging.info("Executando: ALTER TABLE...")
            db.session.execute(sql_etapa_1_alter)

            logging.info("Executando: UPDATE com a lógica de detecção robusta...")
            db.session.execute(sql_etapa_1_update)

        logging.info("ETAPA 1 concluída. Tabela 'dim_localizacao' original foi modificada e sinalizada.")
    except Exception as e:
        db.session.rollback()
        logging.error(f"ERRO na ETAPA 1: {e}")
        return f"<h1>Ocorreu um erro na Etapa 1 (Sinalização da tabela original)</h1><p>{e}</p>"

    # --- ETAPA 2: CRIAR A VIEW 'LIMPA' (SQL) - VERSÃO CORRIGIDA ---
    logging.info("ETAPA 2: Recriando a VIEW 'dim_localizacao_limpa'...")

    # 2a. APAGA a VIEW antiga com segurança para evitar o erro de schema.
    sql_etapa_2_drop = text("""
                            DROP VIEW IF EXISTS public_analytics.dim_localizacao_limpa;
                            """)

    # 2b. CRIA a nova VIEW, fazendo o JOIN para incluir o nome do estado.
    sql_etapa_2_create = text("""
                              CREATE VIEW public_analytics.dim_localizacao_limpa AS
                              SELECT l.id_localizacao,
                                     l.id_estado,
                                     l.cidade,
                                     e.estado, -- Adiciona o nome do estado, necessário para a Etapa 3
                                     l.chave_estado_cidade_key,
                                     l.dq_status
                              FROM public_analytics.dim_localizacao AS l
                                       JOIN
                                   public_analytics.dim_estado AS e ON l.id_estado = e.id_estado
                              WHERE l.dq_status = 'VALID';
                              """)
    try:
        with db.session.begin():
            logging.info("Executando: DROP VIEW IF EXISTS...")
            db.session.execute(sql_etapa_2_drop)

            logging.info("Executando: CREATE VIEW...")
            db.session.execute(sql_etapa_2_create)

        logging.info("ETAPA 2 concluída. VIEW 'dim_localizacao_limpa' recriada com sucesso.")
    except Exception as e:
        db.session.rollback()
        logging.error(f"ERRO na ETAPA 2: {e}")
        return f"<h1>Ocorreu um erro na Etapa 2 (Recriação da VIEW)</h1><p>{e}</p>"

    # --- ETAPA 3: ENRIQUECER OS CLIENTES (Pandas) ---
    logging.info("ETAPA 3: Enriquecendo a tabela de clientes...")
    try:
        query_clientes = text("SELECT * FROM public.clientes_bruto")
        query_local_limpa = text("SELECT * FROM public_analytics.dim_localizacao_limpa")

        with db.engine.connect() as conn:
            df_clientes = pd.read_sql(query_clientes, conn)
            df_local_limpa = pd.read_sql(query_local_limpa, conn)

        # CORREÇÃO: Aplicamos a mesma limpeza aqui para garantir que a chave de junção seja idêntica
        df_clientes['chave_estado_cidade_key'] = (
                df_clientes['cidade'].str.strip().str.lower().fillna('') + "_" + df_clientes[
            'estado'].str.strip().str.lower().fillna('')
        )

        # O merge agora vai funcionar corretamente
        df_clientes_enriquecido = pd.merge(
            df_clientes,
            df_local_limpa[['id_localizacao', 'chave_estado_cidade_key']],
            on='chave_estado_cidade_key',
            how='left'
        )

        nome_tabela_nova = 'clientes_enriquecido'
        schema_nome = 'public'

        df_clientes_enriquecido.to_sql(
            nome_tabela_nova,
            db.engine,
            schema=schema_nome,
            if_exists='replace',
            index=False
        )
        logging.info("ETAPA 3 concluída.")
        return "<h1>ETL Concluído com Sucesso!</h1>"

    except Exception as e:
        logging.error(f"ERRO na ETAPA 3: {e}")
        return f"<h1>Ocorreu um erro na Etapa 3 (Enriquecimento)</h1><p>{e}</p>"

@app.route('/listar-duplicatas')
def listar_duplicatas():
    """
    Endpoint GET para listar todos os registros da dimensão de localização
    que foram sinalizados como 'DUPLICATE_ERROR' pelo processo de ETL.
    """
    logging.info("Requisição recebida para /listar-duplicatas...")

    # SQL para selecionar apenas os registros "sujos"
    # Nós ordenamos pela chave e pelo ID para que você possa ver
    # os grupos de duplicatas juntos.
    sql_query_duplicatas = text("""
                                SELECT *
                                FROM public_analytics.dim_localizacao_suja_com_status
                                WHERE dq_status = 'DUPLICATE_ERROR'
                                ORDER BY chave_estado_cidade_key, id_localizacao;
                                """)

    try:
        # Usamos o Pandas para ler o SQL e converter para HTML
        with db.engine.connect() as conn:
            df_duplicatas = pd.read_sql(sql_query_duplicatas, conn)

        if df_duplicatas.empty:
            logging.info("Nenhuma duplicata encontrada.")
            return (
                "<h1>Nenhum Registro Duplicado Encontrado</h1>"
                "<p>A tabela 'dim_localizacao_suja_com_status' não contém registros com o status 'DUPLICATE_ERROR'.</p>"
            )

        logging.info(f"Encontradas {len(df_duplicatas)} duplicatas. Exibindo...")

        # Converte o DataFrame do Pandas em uma tabela HTML bonita
        html_table = df_duplicatas.to_html(index=False, classes='table table-striped', border=1)

        return (
            f"<h1>Lista de Localizações Duplicadas (Sinalizadas como 'DUPLICATE_ERROR')</h1>"
            f"<p>Estes são os registros que foram identificados como duplicatas e <b>não</b> estão sendo usados no dashboard final.</p>"
            f"<hr>{html_table}"
        )

    except Exception as e:
        # Isso vai acontecer se a tabela ainda não tiver sido criada
        logging.error(f"ERRO ao listar duplicatas: {e}")
        return (
            f"<h1>Ocorreu um erro ao buscar duplicatas</h1>"
            f"<p>{e}</p>"
            f"<p><b>Dica:</b> Você já rodou a rota <a href='/processar-etl-completo'>/processar-etl-completo</a> pelo menos uma vez?</p>"
        )
if __name__ == '__main__':
    app.run(debug=True)